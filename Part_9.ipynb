{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Predictors in Scikit-learn\n",
    "## Guest lecturer: Matteo Bodini\n",
    "\n",
    "Let's introduce Tree Predictors (a.k.a. Decision Trees) in Scikit-learn. The following topics are included in this notebook:\n",
    "\n",
    "- Basic visualization of data\n",
    "\n",
    "- One Hot Encoding\n",
    "\n",
    "- Modelling a decision tree with default parameters\n",
    "\n",
    "- Creating a visual tree to present the decision tree\n",
    "\n",
    "- Results of many decision tree models on an available dataset\n",
    "\n",
    "- Overfitting control through pre-pruning techniques\n",
    "\n",
    "## Our case study\n",
    "\n",
    "We focus on students performance in math exams, and analyze a dataset containing marks obtained by students in college. The goal is to understand the influence of various factors (like economic, personal, social, parents' background and test preparation) on the students performance.\n",
    "\n",
    "A tree classifier is trained to predict the success in a math exam of a student depending on the above and other features.\n",
    "\n",
    "The model is first trained by using only default parameters. Then, we see how to reduce overfitting through pre-pruning techniques, which are often used with these models instead of the more standard cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "We need a couple of additional libraries to display tree classifiers. Graphviz is a tool for drawing graphics and pydotplus is a module to Graphviz’s Dot language. Here are the code lines to install them:\n",
    "- `conda install python-graphviz`\n",
    "- `conda install -c conda-forge pydotplus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "import numpy as np\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Displaying the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'Datasets/StudentsPerformance.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ecceacd8b4c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Datasets/StudentsPerformance.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'Datasets/StudentsPerformance.csv' does not exist"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"Datasets/StudentsPerformance.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "We briefly analyze the dataset using Seaborn, a Python data visualization library based on Matplotlib providing a high-level interface for drawing graphics (https://seaborn.pydata.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"gender\", data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"race/ethnicity\", data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(y=\"parental level of education\", data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"lunch\", data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"test preparation course\", data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we look at the univariate distribution of math scores. A convenient way draw univariate distributions in Seaborn is the `distplot()` function. By default, this draws a histogram and fits a kernel density estimate (KDE is a nonparametric way for estimating the density of a random variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(dataset[\"math score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Let's create a new feature `math grade`. `math grade` is `Pass` if `math score` is above 60, oterwise it is `Fail`. We the remove the columns used to compute the new feature and check the dataset again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"math grade\"] = \"\"\n",
    "dataset.loc[(dataset[\"math score\"] >= 60), \"math grade\"] = \"Pass\"\n",
    "dataset.loc[(dataset[\"math score\"] < 60), \"math grade\"] = \"Fail\"\n",
    "dataset.drop(columns=['math score', 'reading score', 'writing score'], inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding\n",
    "\n",
    "Scikit-learn uses only continuous numerical features.\n",
    "\n",
    "In our dataset, however, we have categorical features. For example, the `race` feature has values `group A`, `group B`, `group C`, `group D`, and `group E`. Using the standard label encoding, these values are mapped to the integers from $1$ to $5$. This can cause problems because tests based on this feature can only use groupings of `race` values based on the ordering induced by the label encoding. Hence, while `race in {group D, group E}` can be implemented as `race > 2`, `race in {group A, group C}` cannot be implemented.\n",
    "\n",
    "One-hot encoding solves this problem by associating a new binary feature for each value of the categorical feature. Hence `race` gets replaced by `race_A`, `race_B` and so on until `race_D`. Then the test `race in {group A, group C}` can be implemented using sequences of tests based on `race_A` and `race_D`.\n",
    "\n",
    "The Pandas function `get_dummies()` whose first argument is a column of a DataFrame (i.e., a Series) creates a new DataFrame with as many binary columns as needed to implement the one-hot encoding of the values found in the column. The flag `drop_first=True` creates $k-1$ binary features $x_1,\\ldots,x_{k-1}$ for a categorical feature $x$ with $k$ many distinct values $v_1,\\dots,v_k$, where the $(0,\\ldots,0)$ one-hot encoding corresponds to $x = v_1$.\n",
    "\n",
    "Finally, the `join()` method adds the DataFrame with the new columns to the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(dataset['gender'], prefix='gender', drop_first=True)\n",
    "dataset = dataset.join(one_hot)\n",
    "one_hot = pd.get_dummies(dataset['race/ethnicity'], prefix='race/ethnicity', drop_first=True)\n",
    "dataset = dataset.join(one_hot)\n",
    "one_hot = pd.get_dummies(dataset['parental level of education'], prefix='parental level of education', drop_first=True)\n",
    "dataset = dataset.join(one_hot)\n",
    "one_hot = pd.get_dummies(dataset['lunch'], prefix='lunch', drop_first=True)\n",
    "dataset = dataset.join(one_hot)\n",
    "one_hot = pd.get_dummies(dataset['test preparation course'], prefix='test preparation course', drop_first=True)\n",
    "dataset = dataset.join(one_hot)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset into training and test sets with proportion $70\\%$ and $30\\%$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(dataset, test_size=0.30, random_state=21)\n",
    "y_train = data_train[\"math grade\"].values\n",
    "X_train = data_train.drop(columns=['math grade']).values\n",
    "y_test = data_test[\"math grade\"].values\n",
    "X_test = data_test.drop(columns=['math grade']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning algorithm is initialized with the default values of `DecisionTreeClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                               max_depth=None, min_samples_split=2, \n",
    "                               min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                               max_features=None, random_state=None, \n",
    "                               max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                               min_impurity_split=None, class_weight=None, \n",
    "                               presort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run the learning algorithm on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train[:,5:], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Next, we use the learned model to predict the points in the test set, compute the accuracy, and print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test[:,5:])\n",
    "print(\"Model Accuracy: %.2f\" % (accuracy_score(y_test,y_pred)*100), \"%\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_pred),\n",
    "                   columns=['prediction/fail', 'prediction/pass'],\n",
    "                   index=['actual/fail', 'actual/pass']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model accuracy is $\\sim 55\\%$. We now compute the training error and compare it with the results from test set. The purpose is to check whether there is an overfitting or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train[:,5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Accuracy: %.2f\" % (accuracy_score(y_train,y_pred_train)*100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, $\\sim 56\\%$ and $\\sim 80\\%$ are quite different: $\\sim 56\\%$ is almost a coin flip! On the other hand, $\\sim 80\\%$ is a promising accuracy rate.\n",
    "\n",
    "So we are definitely overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph of Decision Tree\n",
    "\n",
    "We can simply visualize a decision tree using the Python module ```pydotplus``` and the module ```graphviz```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(model, out_file=dot_data, filled=True, rounded=True, special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and reuse models\n",
    "\n",
    "After training a Scikit-learn model, it is desirable to have a way to save the model for future use without having to retrain. We can save a model with Pickle (https://docs.python.org/3/library/pickle.html#module-pickle).\n",
    "\n",
    "Pickle is used for serializing and de-serializing Python object structures. Serialization refers to the process of converting an object in memory to a byte stream that can be stored on disk or sent over a network. Later on, this stream can then be retrieved and de-serialized back to a Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'saved_model.pickle'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now re-load the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "y_pred = loaded_model.predict(X_test[:,5:])\n",
    "print(\"Model Accuracy: %.2f\" % (accuracy_score(y_test,y_pred)*100), \"%\")\n",
    "dot_data = StringIO()\n",
    "export_graphviz(loaded_model, out_file=dot_data, filled=True, rounded=True, special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Tree Classifier Parameters\n",
    "\n",
    "We look at some of the parameters for Tree Classifiers.\n",
    "\n",
    "In order to explore these parameters, we will analyze 8 tree classifier models. \n",
    "\n",
    "Recall that the initial model was run with default parameters and had an accuracy of $\\sim 55\\%$.\n",
    "\n",
    "In other models we change the following parameters:\n",
    "\n",
    "- ```max_depth```,\n",
    "- ```min_samples_split```,\n",
    "- ```min_samples_leaf```,\n",
    "- ```max_leaf_nodes```,\n",
    "- ```gini + min_impurity_decrease```,\n",
    "- ```entropy + min_impurity_decrease```.\n",
    "\n",
    "Each parameter's best value brings the model accuracy almost to the same level, $\\sim 68\\%$. But the sizes of the resulting trees can be quite different.\n",
    "\n",
    "## Initial model\n",
    "\n",
    "The first model is trained with default parameters of the learning algorithm. The resulting tree classifier is huge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tree pictorially shows the effects of overfitting. Predictions on training set give an accuracy of $\\sim 80\\%$ vs. a test set accuracy of $\\sim 55\\%$.\n",
    "\n",
    "## Model #2\n",
    "\n",
    "### criterion: string, optional (default=”gini”)\n",
    "Possible options are \"gini\" and \"entropy\". Both indices depend on the leaf purity (predominance of a label over the others among the training examples routed to that leaf). The purer the leaf, the smaller the values of both gini and entropy. Tree algorithms split leaves as long as this value decreases, until it reaches zero or fulfills some stopping criterion. We will only use gini in the rest of this notebook.\n",
    "\n",
    "### max_depth: int or None, optional (default=None)\n",
    "The maximum depth of the tree. If `None`, then leaves are expanded until all leaves are pure.\n",
    "\n",
    "Now we study the effect of changing the maximum depth from $1$ to $15$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_parameter_name = 'max_depth'\n",
    "c_parameter_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "c_best_parameter = 0\n",
    "c_best_accuracy = 0\n",
    "c_worst_parameter = 0\n",
    "c_worst_accuracy = 100\n",
    "\n",
    "df = pd.DataFrame(columns=[c_parameter_name, 'accuracy'])\n",
    "\n",
    "for input_parameter in c_parameter_values:\n",
    "    model = DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                   max_depth=input_parameter, min_samples_split=2, \n",
    "                                   min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                   max_features=None, random_state=21, \n",
    "                                   max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                   min_impurity_split=None, class_weight=None, \n",
    "                                   presort=False)\n",
    "\n",
    "    model.fit(X_train[:,5:], y_train)\n",
    "    y_pred = model.predict(X_test[:,5:])\n",
    "    acc_score = accuracy_score(y_test,y_pred)*100\n",
    "    df = df.append({c_parameter_name : input_parameter , 'accuracy' : acc_score}, ignore_index=True)\n",
    "    if acc_score > c_best_accuracy:\n",
    "        c_best_accuracy = acc_score\n",
    "        c_best_parameter = input_parameter\n",
    "        c_best_model = model\n",
    "    if acc_score < c_worst_accuracy:\n",
    "        c_worst_accuracy = acc_score\n",
    "        c_worst_parameter = input_parameter\n",
    "        c_worst_model = model\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.pointplot(x=c_parameter_name, y=\"accuracy\", data=df)\n",
    "title = 'Model #2 test accuracy(%) vs ' + c_parameter_name + ' parameter'\n",
    "plt.title(title)\n",
    "plt.xticks(rotation= 90)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BEST PERFORMANCE TREE,\", c_parameter_name, \"=\", c_best_parameter, \", accuracy = %.2f\" % (c_best_accuracy))\n",
    "dot_data = StringIO()\n",
    "export_graphviz(c_best_model, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest accuracy is achieved for ```max_depth=2```.\n",
    "\n",
    "The accuracy vs. ```max_depth``` plot tells us that, whenever training accuracy does not change much with the depth, then test accuracy decreases with the increase of depth, so that lower depth models exhibit smaller risks than higher depth models.\n",
    "\n",
    "Clearly, in order to avoid underfitting we should let the tree depth increase until the training accuracy is small enough.\n",
    "\n",
    "## Model #3\n",
    "\n",
    "### min_samples_split : int, float, optional (default=2)\n",
    "This is the minimum number of examples required to split a node. If this parameter is set to 20, then any leaf which has less than 20 training examples routed to it will not be split.\n",
    "\n",
    "We explore values of this parameter from $5$ to $400$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_parameter_name = 'min_samples_split'\n",
    "c_parameter_values = [5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,\n",
    "                      100,105,110,115,120,125,130,135,140,200,250,300,350,400]\n",
    "c_best_parameter = 0\n",
    "c_best_accuracy = 0\n",
    "c_worst_parameter = 0\n",
    "c_worst_accuracy = 100\n",
    "\n",
    "df = pd.DataFrame(columns=[c_parameter_name, 'accuracy'])\n",
    "\n",
    "for input_parameter in c_parameter_values:\n",
    "    model = DecisionTreeClassifier(min_samples_split=input_parameter, random_state=21)\n",
    "\n",
    "    model.fit(X_train[:,5:], y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test[:,5:])\n",
    "    \n",
    "    acc_score = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "    df = df.append({c_parameter_name : input_parameter , 'accuracy' : acc_score}, ignore_index=True)\n",
    "    \n",
    "    if acc_score > c_best_accuracy:\n",
    "        c_best_accuracy = acc_score\n",
    "        c_best_parameter = input_parameter\n",
    "        c_best_model = model\n",
    "        \n",
    "    if acc_score < c_worst_accuracy:\n",
    "        c_worst_accuracy = acc_score\n",
    "        c_worst_parameter = input_parameter\n",
    "        c_worst_model = model\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.pointplot(x=c_parameter_name, y=\"accuracy\", data=df)\n",
    "title = 'Model #3 test accuracy(%) vs ' + c_parameter_name + ' parameter'\n",
    "plt.title(title)\n",
    "plt.xticks(rotation= 90)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BEST PERFORMANCE TREE,\", c_parameter_name, \"=\", c_best_parameter, \", accuracy = %.2f\" % (c_best_accuracy))\n",
    "dot_data = StringIO()\n",
    "export_graphviz(c_best_model, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final test accuracy is similar to the one we got by tuning ```max_depth```.\n",
    "\n",
    "Any value for `min_samples_split` between $40$ and $200$ looks OK. Overfitting starts at values below $40$.\n",
    "\n",
    "## Model #4\n",
    "\n",
    "### min_samples_leaf : int, float, optional (default=1)\n",
    "The minimum number of training examples required to create a new leaf.\n",
    "\n",
    "We explore values from $5$ to $200$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_parameter_name = 'min_samples_leaf'\n",
    "c_parameter_values = [5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100,150,200]\n",
    "c_best_parameter = 0\n",
    "c_best_accuracy = 0\n",
    "c_worst_parameter = 0\n",
    "c_worst_accuracy = 100\n",
    "\n",
    "df = pd.DataFrame(columns=[c_parameter_name, 'accuracy'])\n",
    "\n",
    "for input_parameter in c_parameter_values:\n",
    "    model = DecisionTreeClassifier(min_samples_leaf=input_parameter, random_state=21)\n",
    "\n",
    "    model.fit(X_train[:,5:], y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test[:,5:])\n",
    "    \n",
    "    acc_score = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "    df = df.append({c_parameter_name : input_parameter , 'accuracy' : acc_score}, ignore_index=True)\n",
    "    \n",
    "    if acc_score > c_best_accuracy:\n",
    "        c_best_accuracy = acc_score\n",
    "        c_best_parameter = input_parameter\n",
    "        c_best_model = model\n",
    "        \n",
    "    if acc_score < c_worst_accuracy:\n",
    "        c_worst_accuracy = acc_score\n",
    "        c_worst_parameter = input_parameter\n",
    "        c_worst_model = model\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.pointplot(x=c_parameter_name, y=\"accuracy\", data=df)\n",
    "title = 'Model #4 test accuracy(%) vs ' + c_parameter_name + ' parameter'\n",
    "plt.title(title)\n",
    "plt.xticks(rotation= 90)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BEST PERFORMANCE TREE,\", c_parameter_name, \"=\", c_best_parameter, \", accuracy = %.2f\" % (c_best_accuracy))\n",
    "dot_data = StringIO()\n",
    "export_graphviz(c_best_model, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not see a big difference in performance. Values of ```min_samples_leaf``` between $35$ and $100$ look all OK.\n",
    "\n",
    "## Model #5\n",
    "\n",
    "### max_leaf_nodes : int or None, optional (default=None)\n",
    "Maximum number of leaves in a tree.\n",
    "\n",
    "We limit this number to values between $2$ and $20$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_parameter_name = 'max_leaf_nodes'\n",
    "c_parameter_values = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "c_best_parameter = 0\n",
    "c_best_accuracy = 0\n",
    "c_worst_parameter = 0\n",
    "c_worst_accuracy = 100\n",
    "\n",
    "df = pd.DataFrame(columns=[c_parameter_name, 'accuracy'])\n",
    "\n",
    "for input_parameter in c_parameter_values:\n",
    "    model = DecisionTreeClassifier(max_leaf_nodes=input_parameter, random_state=21)\n",
    "\n",
    "    model.fit(X_train[:,5:], y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test[:,5:])\n",
    "    \n",
    "    acc_score = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "    df = df.append({c_parameter_name : input_parameter , 'accuracy' : acc_score}, ignore_index=True)\n",
    "    \n",
    "    if acc_score > c_best_accuracy:\n",
    "        c_best_accuracy = acc_score\n",
    "        c_best_parameter = input_parameter\n",
    "        c_best_model = model\n",
    "        \n",
    "    if acc_score < c_worst_accuracy:\n",
    "        c_worst_accuracy = acc_score\n",
    "        c_worst_parameter = input_parameter\n",
    "        c_worst_model = model\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.pointplot(x=c_parameter_name, y=\"accuracy\", data=df)\n",
    "title = 'Model #5 test accuracy(%) vs ' + c_parameter_name + ' parameter'\n",
    "plt.title(title)\n",
    "plt.xticks(rotation= 90)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BEST PERFORMANCE TREE,\", c_parameter_name, \"=\", c_best_parameter, \", accuracy = %.2f\" % (c_best_accuracy))\n",
    "dot_data = StringIO()\n",
    "export_graphviz(c_best_model, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are two maxima. One at ```max_leaf_nodes=4``` and one at ```max_leaf_nodes=14```.\n",
    "\n",
    "\n",
    "## Model #6\n",
    "\n",
    "### min_impurity_decrease : float, optional (default=0.)\n",
    "One of the most effective parameters. Either gini or entropy is used to calculate the purity of a split.\n",
    "\n",
    "Suppose there are $100$ training examples, and $20$ of them are routed to the leaf we are considering to split, of these $20$ examples $12$ are positive and $8$ are negative. \n",
    "\n",
    "- Step 1: calculate gini for the leaf:\n",
    "\n",
    "$$\\text{Fraction of positives} = 12 / 20 = 0.6$$\n",
    "$$\\text{Fraction of negatives} = 8 / 20 = 0.4$$\n",
    "$$G = 0.6 \\times 0.4 + 0.4 \\times 0.6 = 0.48$$\n",
    "\n",
    "- Step 2: suppose that by splitting the leaf using a specific feature, $13$ examples ($11$ yes and $2$ no) are routed to the left child, and $7$ examples ($1$ positive and $6$ negative) are routed to the right child.\n",
    "\n",
    "Left child:\n",
    "$$\\text{Fraction of positives} = 11 / 13 = 0.85$$\n",
    "$$\\text{Fraction of negatives} = 2 / 13 = 0.15$$\n",
    "$$G_{left} = 0.85 \\times 0.15 + 0.15 \\times 0.85 = 0.255$$\n",
    "Right child: \n",
    "$$\\text{Fraction of positives} = 6 / 7 = 0.86$$\n",
    "$$\\text{Fraction of negatives} = 1 / 7 = 0.14$$\n",
    "$$G_{right} = 0.86 \\times 0.14 + 0.14 \\times 0.86 = 0.241$$\n",
    "\n",
    "- Step 3: calculate the weighted decrease of gini:\n",
    "$N_t / N \\times (G - N_{t_R} / N_t \\times G_{right} - N_{t_L} / N_t \\times G_{left})$\n",
    "where $N$ is the total number of examples, $N_t$ is the number of examples at the current leaf, $N_{t_L}$ is the number of examples in the left child, and $N_{t_R}$ is the number of examples in the right child.\n",
    "$$20 / 100 \\times (0.48 - 7 / 20 \\times 0.241 - 13 / 20 \\times 0.255) = 0.046$$\n",
    "\n",
    "- Step 4: If the biggest decrease in gini over all possible features is bigger than ```min_impurity_decrease```, then the leaf is split using the feature maximizing the decrease.\n",
    "\n",
    "When there are no more possible splits achieving a decrease in gini bigger than `min_impurity_decrease`, then the tree stops growing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_parameter_name = 'min_impurity_decrease'\n",
    "c_parameter_values = [0.00005,0.0001,0.0002,0.0005,0.001,0.0015,0.002,0.005,0.01]\n",
    "c_best_parameter = 0\n",
    "c_best_accuracy = 0\n",
    "c_worst_parameter = 0\n",
    "c_worst_accuracy = 100\n",
    "\n",
    "df = pd.DataFrame(columns=[c_parameter_name, 'accuracy'])\n",
    "\n",
    "for input_parameter in c_parameter_values:\n",
    "    model = DecisionTreeClassifier(min_impurity_decrease=input_parameter, random_state=21)\n",
    "\n",
    "    model.fit(X_train[:,5:], y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test[:,5:])\n",
    "    \n",
    "    acc_score = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "    df = df.append({c_parameter_name : input_parameter , 'accuracy' : acc_score}, ignore_index=True)\n",
    "    \n",
    "    if acc_score > c_best_accuracy:\n",
    "        c_best_accuracy = acc_score\n",
    "        c_best_parameter = input_parameter\n",
    "        c_best_model = model\n",
    "        \n",
    "    if acc_score < c_worst_accuracy:\n",
    "        c_worst_accuracy = acc_score\n",
    "        c_worst_parameter = input_parameter\n",
    "        c_worst_model = model\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.pointplot(x=c_parameter_name, y=\"accuracy\", data=df)\n",
    "title = 'Model #6 test accuracy(%) vs ' + c_parameter_name + ' parameter'\n",
    "plt.title(title)\n",
    "plt.xticks(rotation= 90)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BEST PERFORMANCE TREE,\", c_parameter_name, \"=\", c_best_parameter, \", accuracy = %.2f\" % (c_best_accuracy))\n",
    "dot_data = StringIO()\n",
    "export_graphviz(c_best_model, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no improvement. On the other hand, ```min_impurity_decrease``` is somewhat more reliable than other parameters.\n",
    "\n",
    "What can we do more? We can try entropy as criterion as opposed to gini.\n",
    "\n",
    "### Model #7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_parameter_name = 'min_impurity_decrease'\n",
    "c_parameter_values = [0.0005,0.001,0.002,0.005,0.01,0.02,0.05,0.1,0.15,0.2,0.4]\n",
    "c_best_parameter = 0\n",
    "c_best_accuracy = 0\n",
    "c_worst_parameter = 0\n",
    "c_worst_accuracy = 100\n",
    "\n",
    "df = pd.DataFrame(columns=[c_parameter_name, 'accuracy'])\n",
    "\n",
    "for input_parameter in c_parameter_values:\n",
    "    model = DecisionTreeClassifier(criterion='entropy', min_impurity_decrease=input_parameter, random_state=21)\n",
    "\n",
    "    model.fit(X_train[:,5:], y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test[:,5:])\n",
    "    \n",
    "    acc_score = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "    df = df.append({c_parameter_name : input_parameter , 'accuracy' : acc_score}, ignore_index=True)\n",
    "    \n",
    "    if acc_score > c_best_accuracy:\n",
    "        c_best_accuracy = acc_score\n",
    "        c_best_parameter = input_parameter\n",
    "        c_best_model = model\n",
    "        \n",
    "    if acc_score < c_worst_accuracy:\n",
    "        c_worst_accuracy = acc_score\n",
    "        c_worst_parameter = input_parameter\n",
    "        c_worst_model = model\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.pointplot(x=c_parameter_name, y=\"accuracy\", data=df)\n",
    "title = 'Model #7 test accuracy(%) vs ' + c_parameter_name + ' parameter'\n",
    "plt.title(title)\n",
    "plt.xticks(rotation= 90)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BEST PERFORMANCE TREE,\", c_parameter_name, \"=\", c_best_parameter, \", accuracy = %.2f\" % (c_best_accuracy))\n",
    "dot_data = StringIO()\n",
    "export_graphviz(c_best_model, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy gives results similar to gini.\n",
    "\n",
    "We can try a last model combining some of the parameters we have used in our previous models.\n",
    "\n",
    "## Model #8\n",
    "\n",
    "Since entropy gives slightly better results than gini, we choose entropy for impurity calculations. The other two parameters are ```min_samples_leaf``` and ```min_impurity_decrease```. We choose the best values for these parameters basd on our previous experiments.\n",
    "\n",
    "* Set criterion='entropy'\n",
    "* Set min_samples_leaf=35\n",
    "* Set min_impurity_decrease=0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion='entropy', splitter='best', \n",
    "                               max_depth=None, min_samples_split=2, \n",
    "                               min_samples_leaf=35, min_weight_fraction_leaf=0.0, \n",
    "                               max_features=None, random_state=21, \n",
    "                               max_leaf_nodes=None, min_impurity_decrease=0.005, \n",
    "                               min_impurity_split=None, class_weight=None, \n",
    "                               presort=False)\n",
    "\n",
    "model.fit(X_train[:,5:], y_train)\n",
    "\n",
    "y_pred = model.predict(X_test[:,5:])\n",
    "print(\"Model #8 test accuracy: %.2f\" % (accuracy_score(y_test,y_pred)*100), \"%\")\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(model, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no improvement in accuracy, however:\n",
    "\n",
    "- usually, smaller trees are preferrable: smaller trees typically have lower variance and better generalization capability.\n",
    "- using ```min_impurity_decrease``` in tree classifiers we let the tree grow only if there is room for improvement. This is reasonable compared to other pre-pruning criteria.\n",
    "- Using ```min_samples_leaf``` with ```min_impurity_decrease``` is a good combination. Even if there is room to go further, the tree is stopped before creating leaves based on a very small number of training examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
